{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2f7bffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "114e65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('cardio_train.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1d02cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: First 5 rows of the dataset:\n",
      "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
      "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
      "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
      "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
      "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
      "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
      "\n",
      "   alco  active  cardio  \n",
      "0     0       1       0  \n",
      "1     0       1       1  \n",
      "2     0       0       1  \n",
      "3     0       1       1  \n",
      "4     0       0       0  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Inspect the first few rows\n",
    "print(\"Step 1: First 5 rows of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d6ac967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Information about the dataset (data types and non-null counts):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70000 entries, 0 to 69999\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           70000 non-null  int64  \n",
      " 1   age          70000 non-null  int64  \n",
      " 2   gender       70000 non-null  int64  \n",
      " 3   height       70000 non-null  int64  \n",
      " 4   weight       70000 non-null  float64\n",
      " 5   ap_hi        70000 non-null  int64  \n",
      " 6   ap_lo        70000 non-null  int64  \n",
      " 7   cholesterol  70000 non-null  int64  \n",
      " 8   gluc         70000 non-null  int64  \n",
      " 9   smoke        70000 non-null  int64  \n",
      " 10  alco         70000 non-null  int64  \n",
      " 11  active       70000 non-null  int64  \n",
      " 12  cardio       70000 non-null  int64  \n",
      "dtypes: float64(1), int64(12)\n",
      "memory usage: 6.9 MB\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Check data types and missing values\n",
    "print(\"\\nStep 2: Information about the dataset (data types and non-null counts):\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f43161b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Descriptive Statistics for all numerical columns:\n",
      "                 id           age        gender        height        weight  \\\n",
      "count  70000.000000  70000.000000  70000.000000  70000.000000  70000.000000   \n",
      "mean   49972.419900  19468.865814      1.349571    164.359229     74.205690   \n",
      "std    28851.302323   2467.251667      0.476838      8.210126     14.395757   \n",
      "min        0.000000  10798.000000      1.000000     55.000000     10.000000   \n",
      "25%    25006.750000  17664.000000      1.000000    159.000000     65.000000   \n",
      "50%    50001.500000  19703.000000      1.000000    165.000000     72.000000   \n",
      "75%    74889.250000  21327.000000      2.000000    170.000000     82.000000   \n",
      "max    99999.000000  23713.000000      2.000000    250.000000    200.000000   \n",
      "\n",
      "              ap_hi         ap_lo   cholesterol          gluc         smoke  \\\n",
      "count  70000.000000  70000.000000  70000.000000  70000.000000  70000.000000   \n",
      "mean     128.817286     96.630414      1.366871      1.226457      0.088129   \n",
      "std      154.011419    188.472530      0.680250      0.572270      0.283484   \n",
      "min     -150.000000    -70.000000      1.000000      1.000000      0.000000   \n",
      "25%      120.000000     80.000000      1.000000      1.000000      0.000000   \n",
      "50%      120.000000     80.000000      1.000000      1.000000      0.000000   \n",
      "75%      140.000000     90.000000      2.000000      1.000000      0.000000   \n",
      "max    16020.000000  11000.000000      3.000000      3.000000      1.000000   \n",
      "\n",
      "               alco        active        cardio  \n",
      "count  70000.000000  70000.000000  70000.000000  \n",
      "mean       0.053771      0.803729      0.499700  \n",
      "std        0.225568      0.397179      0.500003  \n",
      "min        0.000000      0.000000      0.000000  \n",
      "25%        0.000000      1.000000      0.000000  \n",
      "50%        0.000000      1.000000      0.000000  \n",
      "75%        0.000000      1.000000      1.000000  \n",
      "max        1.000000      1.000000      1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Basic Descriptive Statistics\n",
    "print(\"\\nStep 3: Descriptive Statistics for all numerical columns:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "965a8872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Total Duplicated Rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Check for Duplicates\n",
    "n_duplicates = df.duplicated().sum()\n",
    "print(f\"\\nStep 4: Total Duplicated Rows: {n_duplicates}\")\n",
    "\n",
    "if n_duplicates > 0:\n",
    "    # Remove duplicates if found\n",
    "    df = df.drop_duplicates()\n",
    "    print(\"Duplicates removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35c400ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5: Column names after standardization (if any change was needed):\n",
      "['id', 'age', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'cardio']\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Standardize Column Names\n",
    "# Column names are already clean (lowercase, no spaces)\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "print(\"\\nStep 5: Column names after standardization (if any change was needed):\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84af2b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 6: Value Counts for Categorical Columns:\n",
      "\n",
      "Value Counts for 'gender':\n",
      "gender\n",
      "1    45530\n",
      "2    24470\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value Counts for 'cholesterol':\n",
      "cholesterol\n",
      "1    52385\n",
      "2     9549\n",
      "3     8066\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value Counts for 'gluc':\n",
      "gluc\n",
      "1    59479\n",
      "3     5331\n",
      "2     5190\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value Counts for 'smoke':\n",
      "smoke\n",
      "0    63831\n",
      "1     6169\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value Counts for 'alco':\n",
      "alco\n",
      "0    66236\n",
      "1     3764\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value Counts for 'active':\n",
      "active\n",
      "1    56261\n",
      "0    13739\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value Counts for 'cardio':\n",
      "cardio\n",
      "0    35021\n",
      "1    34979\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Value Counts for Categorical Columns\n",
    "categorical_cols = ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'cardio']\n",
    "print(\"\\nStep 6: Value Counts for Categorical Columns:\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\nValue Counts for '{col}':\")\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af987b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7: Age distribution plot saved as 'step_07_age_distribution.png'\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Convert age to years and plot distribution\n",
    "df['age_years'] = (df['age'] / 365.25).astype(int)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.histplot(df['age_years'], kde=True, bins=30)\n",
    "plt.title('Step 7: Age Distribution (in Years)')\n",
    "plt.xlabel('Age in Years')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('step_07_age_distribution.png')\n",
    "plt.close()\n",
    "print(\"Step 7: Age distribution plot saved as 'step_07_age_distribution.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ebeff80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps 8 & 9 (Raw): Numerical distributions plot saved as 'steps_08_09_raw_distributions.png'\n"
     ]
    }
   ],
   "source": [
    "# Step 8 & 9 : Plot Distributions for Height, Weight, ap_hi, ap_lo on RAW data\n",
    "numerical_features = ['height', 'weight', 'ap_hi', 'ap_lo']\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numerical_features):\n",
    "    sns.histplot(df[col], kde=True, ax=axes[i], bins=30)\n",
    "    axes[i].set_title(f'Step {8 if i<2 else 9} (Raw): Distribution of {col.title().replace(\"_\", \" \")}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('steps_08_09_raw_distributions.png')\n",
    "plt.close()\n",
    "print(\"Steps 8 & 9 (Raw): Numerical distributions plot saved as 'steps_08_09_raw_distributions.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b26794c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10: Cardio distribution plot saved as 'step_10_cardio_distribution_raw.png'\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Analyze Target Variable (Raw Data)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='cardio', data=df)\n",
    "plt.title('Step 10: Raw Distribution of Cardiovascular Disease')\n",
    "plt.xlabel('Cardio (0: No Disease, 1: Disease)')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('step_10_cardio_distribution_raw.png')\n",
    "plt.close()\n",
    "print(\"Step 10: Cardio distribution plot saved as 'step_10_cardio_distribution_raw.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf3925ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11: Categorical distributions plot saved as 'step_11_categorical_distributions.png'\n"
     ]
    }
   ],
   "source": [
    "# Step 11: Distribution of Binary/Categorical Features\n",
    "categorical_features = ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(categorical_features):\n",
    "    sns.countplot(x=col, data=df, ax=axes[i])\n",
    "    axes[i].set_title(f\"Step 11: Distribution of {col.title()}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('step_11_categorical_distributions.png')\n",
    "plt.close()\n",
    "print(\"Step 11: Categorical distributions plot saved as 'step_11_categorical_distributions.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb4186ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12: Outlier visualization (raw) saved as 'step_12_outlier_boxplots_raw.png'\n",
      "\n",
      "Step 13: Original rows: 70000. Rows after BP cleaning: 68660\n"
     ]
    }
   ],
   "source": [
    "# Step 12 & 13: Outlier Detection and Handling/Cleaning\n",
    "outlier_cols = ['height', 'weight', 'ap_hi', 'ap_lo']\n",
    "\n",
    "# Step 12: Visualize Outliers (Box Plots on Raw Data)\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(outlier_cols):\n",
    "    sns.boxplot(y=df[col], ax=axes[i])\n",
    "    axes[i].set_title(f'Step 12: Box Plot of {col.title()} (Raw Data)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('step_12_outlier_boxplots_raw.png')\n",
    "plt.close()\n",
    "print(\"Step 12: Outlier visualization (raw) saved as 'step_12_outlier_boxplots_raw.png'\")\n",
    "\n",
    "\n",
    "df_cleaned = df[df['ap_lo'] < df['ap_hi']].copy()\n",
    "\n",
    "df_cleaned = df_cleaned[(df_cleaned['ap_hi'] >= 80) & (df_cleaned['ap_hi'] <= 250)]\n",
    "\n",
    "df_cleaned = df_cleaned[(df_cleaned['ap_lo'] >= 40) & (df_cleaned['ap_lo'] <= 140)]\n",
    "\n",
    "\n",
    "print(f\"\\nStep 13: Original rows: {len(df)}. Rows after BP cleaning: {len(df_cleaned)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd344460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14: Correlation heatmap saved as 'step_14_correlation_heatmap.png'\n"
     ]
    }
   ],
   "source": [
    "# Step 14: Correlation Heatmap\n",
    "# Use the cleaned data and relevant features (including age_years created in Step 7)\n",
    "correlation_features = ['age_years', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'cardio']\n",
    "corr_matrix = df_cleaned[correlation_features].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', linewidths=.5)\n",
    "plt.title('Step 14: Correlation Matrix Heatmap (Cleaned Data)')\n",
    "plt.savefig('step_14_correlation_heatmap.png')\n",
    "plt.close()\n",
    "print(\"Step 14: Correlation heatmap saved as 'step_14_correlation_heatmap.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6de7439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15: Cardio risk vs. age plot saved as 'step_15_cardio_risk_vs_age.png'\n"
     ]
    }
   ],
   "source": [
    "# Step 15: Relationship between Age and Cardio (Risk vs. Age)\n",
    "age_risk = df_cleaned.groupby('age_years')['cardio'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='age_years', y='cardio', data=age_risk, marker='o')\n",
    "plt.title('Step 15: Cardiovascular Disease Risk vs. Age (Cleaned Data)')\n",
    "plt.xlabel('Age in Years')\n",
    "plt.ylabel('Proportion with Cardiovascular Disease (Cardio=1)')\n",
    "plt.grid(True, axis='y', alpha=0.5)\n",
    "plt.savefig('step_15_cardio_risk_vs_age.png')\n",
    "plt.close()\n",
    "print(\"Step 15: Cardio risk vs. age plot saved as 'step_15_cardio_risk_vs_age.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ace580b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16: Categorical risk bar plots saved as 'step_16_categorical_risk_barplots.png'\n"
     ]
    }
   ],
   "source": [
    "# Step 16: Cardio Disease Risk by Categorical Features (Cholesterol & Glucose)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "# Risk by Cholesterol\n",
    "chol_risk = df_cleaned.groupby('cholesterol')['cardio'].mean().reset_index()\n",
    "sns.barplot(x='cholesterol', y='cardio', data=chol_risk, ax=axes[0])\n",
    "axes[0].set_title('Step 16: Cardio Risk by Cholesterol Level')\n",
    "axes[0].set_xlabel('Cholesterol Level (1: Normal, 3: High)')\n",
    "axes[0].set_ylabel('Proportion with Cardio Disease')\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "# Risk by Glucose\n",
    "gluc_risk = df_cleaned.groupby('gluc')['cardio'].mean().reset_index()\n",
    "sns.barplot(x='gluc', y='cardio', data=gluc_risk, ax=axes[1])\n",
    "axes[1].set_title('Step 16: Cardio Risk by Glucose Level')\n",
    "axes[1].set_xlabel('Glucose Level (1: Normal, 3: High)')\n",
    "axes[1].set_ylabel('Proportion with Cardio Disease')\n",
    "axes[1].set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('step_16_categorical_risk_barplots.png')\n",
    "plt.close()\n",
    "print(\"Step 16: Categorical risk bar plots saved as 'step_16_categorical_risk_barplots.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2ea69bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17: BMI vs. Cardio boxplot saved as 'step_17_bmi_vs_cardio_boxplot.png'\n"
     ]
    }
   ],
   "source": [
    "# Step 17: BMI Calculation and Analysis\n",
    "# BMI = weight (kg) / (height (m))^2\n",
    "df_cleaned['bmi'] = df_cleaned['weight'] / (df_cleaned['height'] / 100)**2\n",
    "\n",
    "# Plot BMI vs Cardio\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.boxplot(x='cardio', y='bmi', data=df_cleaned)\n",
    "plt.title('Step 17: BMI vs. Cardiovascular Disease (Cleaned Data)')\n",
    "plt.xlabel('Cardio (0: No Disease, 1: Disease)')\n",
    "plt.ylabel('Body Mass Index (BMI)')\n",
    "plt.savefig('step_17_bmi_vs_cardio_boxplot.png')\n",
    "plt.close()\n",
    "print(\"Step 17: BMI vs. Cardio boxplot saved as 'step_17_bmi_vs_cardio_boxplot.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2432a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18: Blood Pressure vs. Cardio box plots saved as 'step_18_bp_vs_cardio_boxplots.png'\n"
     ]
    }
   ],
   "source": [
    "# Step 18: Blood Pressure vs. Cardio (Box Plots)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "sns.boxplot(x='cardio', y='ap_hi', data=df_cleaned, ax=axes[0])\n",
    "axes[0].set_title('Step 18: Systolic BP (ap_hi) vs. Cardio')\n",
    "axes[0].set_xlabel('Cardio (0: No Disease, 1: Disease)')\n",
    "axes[0].set_ylabel('Systolic BP (ap_hi)')\n",
    "\n",
    "sns.boxplot(x='cardio', y='ap_lo', data=df_cleaned, ax=axes[1])\n",
    "axes[1].set_title('Step 18: Diastolic BP (ap_lo) vs. Cardio')\n",
    "axes[1].set_xlabel('Cardio (0: No Disease, 1: Disease)')\n",
    "axes[1].set_ylabel('Diastolic BP (ap_lo)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('step_18_bp_vs_cardio_boxplots.png')\n",
    "plt.close()\n",
    "print(\"Step 18: Blood Pressure vs. Cardio box plots saved as 'step_18_bp_vs_cardio_boxplots.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92007e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19: Blood Pressure scatter plot saved as 'step_19_bp_scatter_by_cardio.png'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 19: Blood Pressure Scatter Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Sample 10% of the data for a clearer plot\n",
    "df_sample = df_cleaned.sample(frac=0.1, random_state=42)\n",
    "sns.scatterplot(x='ap_hi', y='ap_lo', hue='cardio', data=df_sample, alpha=0.6, palette='Set1', s=20)\n",
    "plt.title('Step 19: Systolic vs. Diastolic BP, Colored by Cardio (Sampled Data)')\n",
    "plt.xlabel('Systolic BP (ap_hi)')\n",
    "plt.ylabel('Diastolic BP (ap_lo)')\n",
    "plt.legend(title='Cardio')\n",
    "plt.savefig('step_19_bp_scatter_by_cardio.png')\n",
    "plt.close()\n",
    "print(\"Step 19: Blood Pressure scatter plot saved as 'step_19_bp_scatter_by_cardio.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d31fe16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20: Combined lifestyle risk heatmap saved as 'step_20_smoke_alco_combined_risk_heatmap.png'\n"
     ]
    }
   ],
   "source": [
    "# Step 20: Smoking/Alcohol and Cardio (Combined Effect)\n",
    "# Calculate the mean of 'cardio' for each combination of 'smoke' and 'alco'\n",
    "combined_risk_pivot = df_cleaned.pivot_table(index='smoke', columns='alco', values='cardio', aggfunc='mean')\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(combined_risk_pivot, annot=True, fmt=\".3f\", cmap='YlOrRd', linewidths=.5)\n",
    "plt.title('Step 20: Cardio Risk by Smoking and Alcohol Consumption')\n",
    "plt.xlabel('Alcohol (0: No, 1: Yes)')\n",
    "plt.ylabel('Smoke (0: No, 1: Yes)')\n",
    "plt.savefig('step_20_smoke_alco_combined_risk_heatmap.png')\n",
    "plt.close()\n",
    "print(\"Step 20: Combined lifestyle risk heatmap saved as 'step_20_smoke_alco_combined_risk_heatmap.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f127deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup: Reconstruct the Cleaned DataFrame from initial EDA steps (7, 13, 17) ---\n",
    "df = pd.read_csv('cardio_train.csv', delimiter=';')\n",
    "df['age_years'] = (df['age'] / 365.25).astype(int)\n",
    "\n",
    "# BP Cleaning: Filter illogical and extreme blood pressure values\n",
    "df_cleaned = df[df['ap_lo'] < df['ap_hi']].copy()\n",
    "df_cleaned = df_cleaned[(df_cleaned['ap_hi'] >= 80) & (df_cleaned['ap_hi'] <= 250)]\n",
    "df_cleaned = df_cleaned[(df_cleaned['ap_lo'] >= 40) & (df_cleaned['ap_lo'] <= 140)]\n",
    "\n",
    "# BMI Calculation\n",
    "df_cleaned['bmi'] = df_cleaned['weight'] / (df_cleaned['height'] / 100)**2\n",
    "\n",
    "# Reset index after cleaning\n",
    "df_cleaned = df_cleaned.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f44549a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 21: Final Cleaning Check (IQR Outlier Removal) ---\n",
      "Removed outliers for height. Current rows: 68155\n",
      "Removed outliers for weight. Current rows: 66470\n",
      "Removed outliers for bmi. Current rows: 65230\n"
     ]
    }
   ],
   "source": [
    "# --- Step 21: Final Cleaning Check (IQR Outlier Removal) ---\n",
    "# Filter remaining outliers in height, weight, and BMI using the IQR method (1.5 * IQR rule).\n",
    "print(\"\\n--- Step 21: Final Cleaning Check (IQR Outlier Removal) ---\")\n",
    "numerical_features_to_check = ['height', 'weight', 'bmi']\n",
    "for col in numerical_features_to_check:\n",
    "    Q1 = df_cleaned[col].quantile(0.25)\n",
    "    Q3 = df_cleaned[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Filter out remaining outliers\n",
    "    df_cleaned = df_cleaned[(df_cleaned[col] >= lower_bound) & (df_cleaned[col] <= upper_bound)]\n",
    "    print(f\"Removed outliers for {col}. Current rows: {len(df_cleaned)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c2572ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 22: Encoding Binary Feature 'gender' ---\n",
      "'gender' converted to 'gender_encoded' (0=Female, 1=Male).\n"
     ]
    }
   ],
   "source": [
    "# --- Step 22: Encoding Binary Feature `gender` ---\n",
    "# Convert gender (1=Female, 2=Male) to standard 0/1 encoding (0=Female, 1=Male).\n",
    "print(\"\\n--- Step 22: Encoding Binary Feature 'gender' ---\")\n",
    "df_cleaned['gender_encoded'] = df_cleaned['gender'].apply(lambda x: 1 if x == 2 else 0)\n",
    "df_cleaned = df_cleaned.drop(columns=['gender'])\n",
    "print(\"'gender' converted to 'gender_encoded' (0=Female, 1=Male).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4653c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 23: Define Feature Sets and Drop Redundant Columns ---\n",
      "Redundant columns ('id', 'age') dropped.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 23: Define Feature Sets and Drop Redundant Columns ---\n",
    "print(\"\\n--- Step 23: Define Feature Sets and Drop Redundant Columns ---\")\n",
    "numerical_features = ['age_years', 'height', 'weight', 'ap_hi', 'ap_lo', 'bmi']\n",
    "# Drop the original age in days and the unnecessary ID column\n",
    "df_cleaned = df_cleaned.drop(columns=['id', 'age'])\n",
    "print(\"Redundant columns ('id', 'age') dropped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "896dbee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 24: Scaling Numerical Features ---\n",
      "Numerical features scaled using StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 24: Scaling Numerical Features ---\n",
    "# Apply StandardScaler to normalize numerical features.\n",
    "print(\"\\n--- Step 24: Scaling Numerical Features ---\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the numerical features\n",
    "df_cleaned[numerical_features] = scaler.fit_transform(df_cleaned[numerical_features])\n",
    "print(\"Numerical features scaled using StandardScaler.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "790d8e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 25: Final Processed DataFrame (Ready for Model Training) ---\n",
      "     height    weight     ap_hi     ap_lo  cholesterol  gluc  smoke  alco  \\\n",
      "0  0.469933 -0.879883 -0.988446 -0.115179            1     1      0     0   \n",
      "1 -1.129308  1.044323  0.842758  0.961388            3     1      0     0   \n",
      "2  0.070123 -0.712561  0.232357 -1.191746            3     1      0     0   \n",
      "3  0.603203  0.793340  1.453159  2.037955            1     1      0     0   \n",
      "4 -1.129308 -1.381850 -1.598847 -2.268314            1     1      0     0   \n",
      "\n",
      "   active  cardio  age_years       bmi  gender_encoded  \n",
      "0       1       0  -0.407563 -1.148244               1  \n",
      "1       1       1   0.330976  1.915268               0  \n",
      "2       0       1  -0.259855 -0.784069               0  \n",
      "3       1       1  -0.702979  0.445697               1  \n",
      "4       0       0  -0.850687 -0.901458               0  \n",
      "\n",
      "Final processed DataFrame saved as 'cardio_processed_final.csv'.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 25: Final DataFrame Assembly (Verification and Save) ---\n",
    "print(\"\\n--- Step 25: Final Processed DataFrame (Ready for Model Training) ---\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "# Output the final processed data to CSV\n",
    "df_cleaned.to_csv('cardio_processed_final.csv', index=False, sep=';')\n",
    "print(\"\\nFinal processed DataFrame saved as 'cardio_processed_final.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42f548e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height;weight;ap_hi;ap_lo;cholesterol;gluc;smoke;alco;active;cardio;age_years;bmi;gender_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.46993259125721304;-0.8798831721394234;-0.988...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.1293076011349006;1.0443231744404002;0.84275...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.07012254315918465;-0.7125608811324822;0.2323...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6032026072898892;0.7933397379299885;1.453159...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.1293076011349006;-1.381850045160247;-1.5988...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65225</th>\n",
       "      <td>0.07012254315918465;0.6260174469230473;1.45315...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65226</th>\n",
       "      <td>0.46993259125721304;0.29137286490916486;-0.378...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65227</th>\n",
       "      <td>2.468982831747355;2.717546084509812;3.28436255...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65228</th>\n",
       "      <td>-0.19641748890616761;-0.043271717104717465;0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65229</th>\n",
       "      <td>0.7364726233225654;-0.043271717104717465;-0.37...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65230 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      height;weight;ap_hi;ap_lo;cholesterol;gluc;smoke;alco;active;cardio;age_years;bmi;gender_encoded\n",
       "0      0.46993259125721304;-0.8798831721394234;-0.988...                                              \n",
       "1      -1.1293076011349006;1.0443231744404002;0.84275...                                              \n",
       "2      0.07012254315918465;-0.7125608811324822;0.2323...                                              \n",
       "3      0.6032026072898892;0.7933397379299885;1.453159...                                              \n",
       "4      -1.1293076011349006;-1.381850045160247;-1.5988...                                              \n",
       "...                                                  ...                                              \n",
       "65225  0.07012254315918465;0.6260174469230473;1.45315...                                              \n",
       "65226  0.46993259125721304;0.29137286490916486;-0.378...                                              \n",
       "65227  2.468982831747355;2.717546084509812;3.28436255...                                              \n",
       "65228  -0.19641748890616761;-0.043271717104717465;0.5...                                              \n",
       "65229  0.7364726233225654;-0.043271717104717465;-0.37...                                              \n",
       "\n",
       "[65230 rows x 1 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cardio_processed_final.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607f997b",
   "metadata": {},
   "source": [
    "# Step 26: Data Preparation for Modeling\n",
    "Define Features (X) and Target (y), then split into Train and Test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e2a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features and Target\n",
    "X = df_cleaned.drop(columns=['cardio'])\n",
    "y = df_cleaned['cardio']\n",
    "\n",
    "# Train-Test Split (80% Train, 20% Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training shape: {X_train.shape}\")\n",
    "print(f\"Testing shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ac3ae6",
   "metadata": {},
   "source": [
    "# Step 27: Train Baseline Models\n",
    "We will train Logistic Regression, Random Forest, Decision Tree, KNN, and Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc1ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Training models...\")\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate probabilities for ROC-AUC if supported\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_test)[:, 1] \n",
    "        roc = roc_auc_score(y_test, y_prob)\n",
    "    else:\n",
    "        roc = 0 # KNN might not support predict_proba in standard call without setup, or others. \n",
    "                # Actually KNN does support it. This is just a safeguard.\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1,\n",
    "        \"ROC AUC\": roc\n",
    "    })\n",
    "    print(f\"{name} trained. Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8477c52",
   "metadata": {},
   "source": [
    "# Step 28: Model Comparison\n",
    "Compare the performance metrics of the trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e298b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "# Visualize Accuracy Comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Accuracy', y='Model', data=results_df, palette='viridis')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xlim(0, 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc123da",
   "metadata": {},
   "source": [
    "# Step 29: Hyperparameter Tuning (Random Forest)\n",
    "Optimize the Random Forest model using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d4b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Make sure RandomForestClassifier is known if run independently, though it was imported in Step 27.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV\n",
    "print(\"Starting Hyperparameter Tuning...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Model\n",
    "best_rf = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Cross-Val Accuracy: {grid_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de648d8c",
   "metadata": {},
   "source": [
    "# Step 30: Final Evaluation\n",
    "Evaluate the tuned Random Forest model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c909398",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict on Test Set\n",
    "y_final_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Final Metrics\n",
    "final_acc = accuracy_score(y_test, y_final_pred)\n",
    "final_f1 = f1_score(y_test, y_final_pred)\n",
    "print(f\"Final Tuned Random Forest Accuracy: {final_acc:.4f}\")\n",
    "print(f\"Final Tuned Random Forest F1 Score: {final_f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "cm = confusion_matrix(y_test, y_final_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix (Tuned Random Forest)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cc2355",
   "metadata": {},
   "source": [
    "# Step 31: Save Model\n",
    "Save the final trained model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bb5b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib\n",
    "joblib.dump(best_rf, 'cardio_model_final.pkl')\n",
    "print(\"Model saved to 'cardio_model_final.pkl'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
